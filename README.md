# cub-scout -- explore and map GitOps clusters

Cub-scout is an open source cluster explorer which is designed to work with existing k8s/gitops clusters as a 'standalone' (read only) tool.  You can also run cub-scout with more features in ['connected' mode](#connecting-cub-scout-confighub), using your (free!) account on [ConfigHub](https://confighub.com).  Or you can [integrate its behaviour](https://github.com/confighub/cub-scout/blob/main/docs/reference/gsf-schema.md) into your own favourite tool.

NOTE: experimental project.  Please send feedback by [opening an issue](https://github.com/confighub/cub-scout/issues) or joining [Discord](https://discord.gg/confighub).  

**Demystify GitOps. See what's really happening in your cluster.**

GitOps is powerful but can be a opaque at times. Where did this Deployment come from? Why isn't my change applying? Is this managed by Git or was it kubectl'd? cub-scout makes the invisible visible.

```bash
brew install confighub/tap/cub-scout
cub-scout map
```

### Quickstart (2 minutes)

1. **Prerequisites:** kubectl access to a cluster (`kubectl get pods` works)
2. **First command:** `cub-scout map` â€” launches interactive TUI
3. **Press `?`** for keyboard shortcuts
4. **Try:** `cub-scout trace deploy/<name> -n <namespace>` on any deployment

---

**Ownership at a glance:**

![cub-scout map dashboard](docs/images/map-dashboard.png)

**Press `w` to see all workloads grouped by owner:**

![cub-scout workloads view](docs/images/map-workloads.png)

Press `T` to trace any resource. Press `4` for deep-dive. Press `?` for help.

---

## The Problem

GitOps tools are powerful but can hide complexity behind layers of abstraction.

**What's obscure:**
- A Deployment exists, but where did it come from? (Kustomization? HelmRelease? kubectl?)
- A change isn't applying, but why? (Source not ready? Reconciliation stuck? Wrong path?)
- Resources exist with no owner â€” who created them and when?
- Dependencies between apps are invisible until something breaks

**What you end up doing:**
- `kubectl get kustomization -A` + `kubectl get helmrelease -A` + `kubectl get application -A`
- Manually checking labels to figure out ownership
- Tribal knowledge: "Oh, that's managed by the platform team's Flux setup"

cub-scout shows you the whole picture in seconds.

---

## The Solution

cub-scout shows you the whole picture in one view.

### Status Dashboard

```bash
cub-scout map status
```

```
  âœ“ ALL HEALTHY   prod-east

  Deployers  5/5
  Workloads  47/47

  OWNERSHIP
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Flux(28) ArgoCD(12) Helm(5) Native(2)
  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘
```

When things go wrong:

```
  ðŸ”¥ 3 FAILURE(S)   prod-east

  Deployers  3/5
  Workloads  44/47

  PROBLEMS
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ— HelmRelease/redis-cache      SourceNotReady
  âœ— Application/payment-api      OutOfSync
  â¸ Kustomization/monitoring     suspended
```

---

### Trace Any Resource to Git

**One command for Flux, ArgoCD, or Helm.** You don't need to know which tool manages a resource.

```bash
cub-scout trace deploy/payment-api -n prod
```

Auto-detects the GitOps tool and shows the full chain: Git repo â†’ Deployer â†’ Workload â†’ Pod

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRACE: Deployment/payment-api                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  ðŸŸ¢ âœ“ GitRepository/platform-config                                 â”‚
â”‚      â”‚ URL: git@github.com:acme/platform-config.git                 â”‚
â”‚      â”‚ Revision: main@sha1:abc123f                                  â”‚
â”‚      â”‚ Status: Artifact is up to date                               â”‚
â”‚      â”‚                                                              â”‚
â”‚      â””â”€â–¶ ðŸŸ¢ âœ“ Kustomization/apps-payment                            â”‚
â”‚              â”‚ Path: ./clusters/prod/apps/payment                   â”‚
â”‚              â”‚ Status: Applied revision main@sha1:abc123f           â”‚
â”‚              â”‚                                                      â”‚
â”‚              â””â”€â–¶ ðŸŸ¢ âœ“ Deployment/payment-api                        â”‚
â”‚                      â”‚ Namespace: prod                              â”‚
â”‚                      â”‚ Status: 3/3 ready                            â”‚
â”‚                      â”‚                                              â”‚
â”‚                      â””â”€â–¶ ReplicaSet/payment-api-7d4b8c              â”‚
â”‚                          â”œâ”€â”€ Pod/payment-api-7d4b8c-abc12 âœ“ Running â”‚
â”‚                          â”œâ”€â”€ Pod/payment-api-7d4b8c-def34 âœ“ Running â”‚
â”‚                          â””â”€â”€ Pod/payment-api-7d4b8c-xyz99 âœ“ Running â”‚
â”‚                                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ðŸŸ¢ âœ“ All levels in sync. Managed by Flux.                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Show deployment history:**

```bash
cub-scout trace deploy/payment-api -n prod --history
```

```
History:
  2026-01-28 10:00  main@sha1:abc123f    deployed    auto-sync
  2026-01-27 14:30  main@sha1:def456a    deployed    manual sync by alice@acme.com
  2026-01-25 09:15  main@sha1:789ghib    deployed    auto-sync
```

History data is fetched from each tool's native storage: ArgoCD `status.history`, Flux `status.history`, Helm release secrets.

---

### Tree Command â€” Multiple Hierarchy Views

```bash
cub-scout tree
```

**Runtime Hierarchy** â€” Deployment â†’ ReplicaSet â†’ Pod:

```
RUNTIME HIERARCHY (47 Deployments)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â”œâ”€â”€ boutique/cart [Flux] 2/2 ready
â”‚   â””â”€â”€ ReplicaSet cart-86f68db776 [2/2]
â”‚       â”œâ”€â”€ Pod cart-86f68db776-hzqgf  âœ“ Running  10.244.0.15
â”‚       â””â”€â”€ Pod cart-86f68db776-mp8kz  âœ“ Running  10.244.0.16
â”œâ”€â”€ boutique/checkout [Flux] 1/1 ready
â”‚   â””â”€â”€ ReplicaSet checkout-5d8f9c7b4 [1/1]
â”‚       â””â”€â”€ Pod checkout-5d8f9c7b4-abc12  âœ“ Running  10.244.0.17
â”œâ”€â”€ monitoring/prometheus [Helm] 1/1 ready
â”‚   â””â”€â”€ ReplicaSet prometheus-7d4b8c [1/1]
â”‚       â””â”€â”€ Pod prometheus-7d4b8c-xyz99  âœ“ Running  10.244.0.18
â””â”€â”€ temp-test/debug-nginx [Native] 1/1 ready
    â””â”€â”€ ReplicaSet debug-nginx-6c5d7b [1/1]
        â””â”€â”€ Pod debug-nginx-6c5d7b-def34  âš  Pending  (no node)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Summary: 47 Deployments â”‚ 189 Pods â”‚ 186 Running â”‚ 3 Pending
```

```bash
cub-scout tree ownership
```

**Ownership Hierarchy** â€” Resources grouped by owner:

```
OWNERSHIP HIERARCHY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Flux (28 resources)
â”œâ”€â”€ boutique/cart             Deployment  âœ“ 2/2 ready
â”œâ”€â”€ boutique/checkout         Deployment  âœ“ 1/1 ready
â”œâ”€â”€ boutique/frontend         Deployment  âœ“ 3/3 ready
â”œâ”€â”€ ingress/nginx-ingress     Deployment  âœ“ 2/2 ready
â””â”€â”€ ... (24 more)

ArgoCD (12 resources)
â”œâ”€â”€ cert-manager/cert-manager   Deployment  âœ“ 1/1 ready
â”œâ”€â”€ argocd/argocd-server        Deployment  âœ“ 1/1 ready
â””â”€â”€ ... (10 more)

Helm (5 resources)
â”œâ”€â”€ monitoring/prometheus       StatefulSet âœ“ 1/1 ready
â”œâ”€â”€ monitoring/grafana          Deployment  âœ“ 1/1 ready
â””â”€â”€ ... (3 more)

Native (2 resources)  âš  ORPHANS
â”œâ”€â”€ temp-test/debug-nginx       Deployment  âœ“ 1/1 ready
â””â”€â”€ kube-system/coredns         Deployment  âœ“ 2/2 ready

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ownership: Flux 60% â”‚ ArgoCD 26% â”‚ Helm 10% â”‚ Native 4%
```

```bash
cub-scout tree suggest
```

**Suggested Organization** â€” Hub/AppSpace recommendation:

```
HUB/APPSPACE SUGGESTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Detected pattern: D2 (Control Plane style)
  â””â”€â”€ clusters/prod, clusters/staging structure

Suggested Hub/AppSpace organization:

  Hub: acme-platform
  â”œâ”€â”€ Space: boutique-prod
  â”‚   â”œâ”€â”€ Unit: cart          (Deployment boutique/cart)
  â”‚   â”œâ”€â”€ Unit: checkout      (Deployment boutique/checkout)
  â”‚   â”œâ”€â”€ Unit: frontend      (Deployment boutique/frontend)
  â”‚   â””â”€â”€ Unit: payment-api   (Deployment boutique/payment-api)
  â”‚
  â”œâ”€â”€ Space: boutique-staging
  â”‚   â””â”€â”€ (clone from boutique-prod with staging values)
  â”‚
  â””â”€â”€ Space: platform
      â”œâ”€â”€ Unit: nginx-ingress   (Deployment ingress/nginx)
      â”œâ”€â”€ Unit: cert-manager    (Deployment cert-manager/cert-manager)
      â””â”€â”€ Unit: monitoring      (StatefulSet monitoring/prometheus)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Next steps:
  1. Review the suggested structure above
  2. Import workloads: cub-scout import -n boutique
  3. View in ConfigHub: cub unit tree --space boutique-prod
```

---

### Discover and Health (Scout-Style Commands)

```bash
cub-scout discover
```

```
WORKLOADS BY OWNER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STATUS  NAMESPACE       NAME              OWNER      MANAGED-BY
âœ“       boutique        cart              Flux       Kustomization/apps
âœ“       boutique        checkout          Flux       Kustomization/apps
âœ“       boutique        frontend          Flux       Kustomization/apps
âœ“       monitoring      prometheus        Helm       Release/kube-prometheus
âœ“       monitoring      grafana           Helm       Release/kube-prometheus
âœ“       cert-manager    cert-manager      ArgoCD     Application/cert-manager
âš        temp-test       debug-nginx       Native     â€” (orphan)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Found: 47 workloads â”‚ Flux(28) ArgoCD(12) Helm(5) Native(2)
```

```bash
cub-scout health
```

```
CLUSTER HEALTH CHECK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DEPLOYER ISSUES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ— HelmRelease/redis-cache      SourceNotReady
    Message: failed to fetch Helm chart: connection refused
    Last attempt: 5 minutes ago

  â¸ Kustomization/monitoring     suspended
    Suspended since: 2026-01-20T10:30:00Z
    Reason: Manual pause for maintenance

WORKLOAD ISSUES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ— temp-test/debug-nginx        0/1 pods ready
    Reason: ImagePullBackOff
    Image: nginx:nonexistent

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Summary: 2 deployer issues â”‚ 1 workload issue â”‚ 1 suspended
```

---

### Scan for Configuration Issues

```bash
cub-scout scan
```

```
CONFIG RISK SCAN: prod-east
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CRITICAL (1)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  [CCVE-2025-0027] Grafana sidecar namespace whitespace error
    Resource: monitoring/ConfigMap/grafana-sidecar
    Impact:   Dashboard injection fails silently
    Fix:      Remove spaces: NAMESPACE="monitoring,grafana"
    Ref:      FluxCon 2025 â€” BIGBANK 3-day outage

WARNING (2)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  [CCVE-2025-0043] Thanos sidecar not uploading to object storage
    Resource: monitoring/StatefulSet/prometheus
    Fix:      Check objstore.yml bucket configuration

  [CCVE-2025-0066] SSL redirect blocking ACME HTTP-01 challenge
    Resource: ingress/Ingress/api-gateway
    Fix:      Add: kubernetes.io/ingress.allow-http: "true"

INFO (1)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  [CCVE-2025-0084] PodDisruptionBudget allows zero available
    Resource: cache/PodDisruptionBudget/redis-pdb
    Fix:      Set minAvailable to at least 1

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Summary: 1 CRITICAL â”‚ 2 WARNING â”‚ 1 INFO
Scanned: 47 resources â”‚ Patterns: 46 active (4,500+ reference)
```

---

## Quick Commands

| Command | What You Get |
|---------|--------------|
| `cub-scout map` | Interactive TUI - press `?` for help |
| `cub-scout discover` | Find workloads by owner (scout-style alias) |
| `cub-scout tree` | Hierarchical views (runtime, git, config) |
| `cub-scout tree suggest` | Suggested Hub/AppSpace organization |
| `cub-scout trace deploy/x -n y` | Full ownership chain to Git source |
| `cub-scout trace deploy/x -n y --history` | Deployment history (who deployed what, when) |
| `cub-scout health` | Check for issues (scout-style alias) |
| `cub-scout scan` | Configuration risk patterns (46 patterns) |
| `cub-scout snapshot --relations` | Export state with dependency graph (GSF format) |

### Tree Views

| View | Shows |
|------|-------|
| `cub-scout tree runtime` | Deployment â†’ ReplicaSet â†’ Pod hierarchies |
| `cub-scout tree ownership` | Resources grouped by GitOps owner |
| `cub-scout tree git` | Git source structure (repos, paths) |
| `cub-scout tree patterns` | Detected GitOps patterns (D2, Arnie, etc.) |
| `cub-scout tree config --space X` | ConfigHub Unit relationships (wraps `cub unit tree`) |
| `cub-scout tree suggest` | Recommended Hub/AppSpace structure |

---

## Keyboard Shortcuts

| Key | View |
|-----|------|
| `s` | Status dashboard |
| `w` | Workloads by owner |
| `o` | Orphans (unmanaged resources) |
| `4` | Deep-dive (resource trees) |
| `5` | App hierarchy (inferred Units) |
| `T` | Trace selected resource |
| `/` | Search |
| `?` | Help |
| `q` | Quit |

---

## Ownership Detection

| Owner | How Detected |
|-------|--------------|
| **Flux** | `kustomize.toolkit.fluxcd.io/*` or `helm.toolkit.fluxcd.io/*` labels |
| **ArgoCD** | `argocd.argoproj.io/instance` label |
| **Helm** | `app.kubernetes.io/managed-by: Helm` (standalone, not Flux-managed) |
| **Crossplane** | `crossplane.io/claim-name` label or `*.crossplane.io` owner refs *(experimental)* |
| **ConfigHub** | `confighub.com/UnitSlug` label |
| **Native** | None of the above (kubectl-applied) |

**Flux sources supported:** GitRepository, OCIRepository, HelmRepository, Bucket

**ArgoCD sources supported:** Git, OCI, Helm charts

**Helm tracing:** For standalone Helm releases (not managed by Flux HelmRelease), cub-scout reads release metadata directly from Kubernetes secrets.

**Crossplane support (experimental):** cub-scout detects Crossplane-managed resources via claim labels, composite references, and owner references to `*.crossplane.io` or `*.upbound.io` API groups. Useful for platform teams managing cloud infrastructure alongside GitOps workloads. See [cross-owner-demo](examples/demos/cross-owner-demo.yaml) for a realistic scenario.

### ConfigHub OCI Registry Support

cub-scout automatically detects and traces resources deployed from ConfigHub acting as an OCI registry:

**ConfigHub OCI URL format:** `oci://oci.{instance}/target/{space}/{target}`

**Example trace output:**
```
  âœ“ ConfigHub OCI/prod/us-west
    â”‚ Space: prod
    â”‚ Target: us-west
    â”‚ Registry: oci.api.confighub.com
    â”‚ Revision: latest@sha1:abc123
    â”‚
    â””â”€â–¶ âœ“ Application/frontend-app
        Status: Synced / Healthy
```

Works with both Flux OCIRepository and ArgoCD Applications pulling from ConfigHub OCI.

---

## See It at Scale

For a realistic demo with 50+ resources, see [docs/getting-started/scale-demo.md](docs/getting-started/scale-demo.md).

```bash
# Deploy the official Flux reference architecture
flux bootstrap github --owner=you --repository=fleet-infra --path=clusters/staging

# Explore with cub-scout
cub-scout map
```

---

## Install

### Homebrew (macOS/Linux)

```bash
brew install confighub/tap/cub-scout
```

### From Source

```bash
git clone https://github.com/confighub/cub-scout.git
cd cub-scout
go build ./cmd/cub-scout
./cub-scout version
```

### Docker

```bash
docker run --rm --network=host \
  -v ~/.kube:/home/nonroot/.kube \
  ghcr.io/confighub/cub-scout map list
```

---

## How It Works

cub-scout uses **deterministic label detection** â€” no AI, no magic:

1. Connect to your cluster via kubectl context
2. List resources across all namespaces
3. Examine labels and annotations on each resource
4. Match against known ownership patterns (Flux, Argo, Helm, etc.)
5. Display results

**Read-only by default.** We only use `Get`, `List`, `Watch` â€” never `Create`, `Update`, `Delete`. See [SECURITY.md](SECURITY.md) for details.

---

## Design Principles

**Wrap, don't reinvent.** cub-scout builds on existing tools rather than replacing them:

| Principle | What It Means |
|-----------|---------------|
| **Use kubectl** | All cluster access goes through your existing kubeconfig |
| **Use cub CLI** | Fleet queries use ConfigHub's `cub` CLI, not a parallel API |
| **Parse, don't guess** | Ownership comes from actual labels, not heuristics |
| **Complement GitOps** | Works alongside Flux, Argo, Helm â€” doesn't compete |

**Why this matters:** Your existing tools, RBAC, and audit trails all still work. cub-scout is a lens, not a replacement.

> **ðŸ§ª Built with AI assistance:** This project was developed with AI pair programming. It's read-only by default, deterministic (no ML inference), and CI-tested. We'd love to hear what you learn using it â€” [open an issue](https://github.com/confighub/cub-scout/issues) or join [Discord](https://discord.gg/confighub).

---

## Connecting cub-scout ConfigHub

cub-scout is an experimental open-source cluster explorer which is designed to work with existing k8s clusters as a 'standalone' (read only) tool.  Or, if you have signed up, we recommended running cub-scout connected to [ConfigHub](https://confighub.com).

| Feature | Standalone | Connected |
|---------|:----------:|:---------:|
| `map` â€” Interactive TUI | âœ“ | âœ“ |
| `trace` â€” Ownership chains | âœ“ | âœ“ |
| `tree` â€” Hierarchy views | âœ“ | âœ“ |
| `scan` â€” Risk patterns | âœ“ | âœ“ |
| `discover` / `health` | âœ“ | âœ“ |
| `snapshot` â€” Export state (GSF) | âœ“ | âœ“ |
| `import` â€” Send to ConfigHub | â€” | âœ“ |
| `fleet` â€” Multi-cluster queries | â€” | âœ“ |
| DRYâ†”WETâ†”LIVE compare | â€” | âœ“ |
| Revision history | â€” | âœ“ |
| Team collaboration | â€” | âœ“ |

**Standalone:** No signup, works forever. Read-only cluster exploration features.

**Connected:** Run `cub auth login` to link to ConfigHub to access more features and import apps.

### How to Connect

To use connected mode features, authenticate your machine with the ConfigHub CLI:

```bash
# Install the ConfigHub CLI (if not already installed)
brew install confighub/tap/cub

# Authenticate (opens browser for login)
cub auth login
```

Once authenticated, cub-scout automatically operates in **connected mode**:

- **Fleet visibility:** Query resources across all clusters your organization has connected to ConfigHub
- **Import workloads:** Send discovered resources to ConfigHub for tracking and collaboration
- **Worker access:** Read from any cluster that ConfigHub is connected to via a [Bridge Worker](https://docs.confighub.com/workers), even without direct kubectl access

Your authentication is stored locally and shared between `cub` and `cub-scout`.

### Verify Connection

Use `cub-scout status` to verify your connection status:

```bash
$ ./cub-scout status
ConfigHub:  â— Connected (alexis@confighub.com)
Cluster:    prod-east
Context:    eks-prod-east
Worker:     â— bridge-prod (connected)
```

JSON output is available for scripting:

```bash
$ ./cub-scout status --json
{
  "mode": "connected",
  "email": "alexis@confighub.com",
  "cluster_name": "prod-east",
  "context": "eks-prod-east",
  "space": "platform-prod",
  "worker": {
    "name": "bridge-prod",
    "status": "connected"
  }
}
```

The TUI also shows connection status in its header:

```
Connected â”‚ Cluster: prod-east â”‚ Context: eks-prod-east â”‚ Worker: â— bridge-prod
```

---

## Documentation

| Doc | Content |
|-----|---------|
| [CLI-GUIDE.md](CLI-GUIDE.md) | Complete command reference |
| [SECURITY.md](SECURITY.md) | Read-only guarantee, RBAC, vulnerability reporting |
| [docs/getting-started/scale-demo.md](docs/getting-started/scale-demo.md) | See cub-scout at scale |
| [docs/howto/scan-for-risks.md](docs/howto/scan-for-risks.md) | Risk scanning (46 patterns) |
| [examples/](examples/) | Demo scenarios |

---

## Contributing

Contributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md).

- **Found a bug?** [Open an issue](https://github.com/confighub/cub-scout/issues)
- **Have an idea?** Start a discussion
- **Want to contribute?** PRs welcome

> **ATTENTION:** Help us keep this project in good readable and usable order please! If you find anything that doesn't seem to fit in, maybe a dangling reference or an old version of the text, please [file an issue](https://github.com/confighub/cub-scout/issues) and we shall clean it up.

---

## Community

- **Discord:** [discord.gg/confighub](https://discord-auth.confighub.net/discord/join)
- **Issues:** [GitHub Issues](https://github.com/confighub/cub-scout/issues)
- **Website:** [confighub.com](https://confighub.com)

---

## License

MIT License â€” see [LICENSE](LICENSE)
